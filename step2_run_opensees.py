# -*- coding: utf-8 -*-
"""
File name      : step2_run_opensees.py
Author         : pc22
Created on     : Sat Dec 27 13:11:43 2025
Last modified  : Sat Dec 27 13:11:43 2025
------------------------------------------------------------
Purpose:
    Automated Time History Analysis (THA) in OpenSeesPy for
    generating structural response datasets under multiple
    column heights and multiple earthquake records, in both
    training and prediction workflows, and for both linear
    and nonlinear structural models.
------------------------------------------------------------
Description:
    This script is the main runner for dynamic time history
    analysis using OpenSeesPy.

    It supports two execution modes:
      1) train  : runs THA for a set of ground motion records
                 intended to produce training datasets.
      2) predict: runs THA for a separate set of records used
                 for model evaluation / comparison.

    It also supports two structural model types:
      - linear   : executes model_linear.py
      - nonlinear: executes model_nonlinear.py

    For each selected column height (H) and each earthquake
    record (.AT2), the script:
      - sets the height via environment variable (H_COL)
      - creates a dedicated output folder: H*/<record_name>/
      - builds the OpenSees model (linear/nonlinear)
      - defines damping and recorders
      - reads and transforms the ground motion record
      - applies the excitation using UniformExcitation
      - runs dynamic analysis via doDynamicAnalysis()
      - saves recorder outputs to the record-specific folder

    The script is designed for batch processing and is robust
    to failures: if an individual record fails, it is logged
    and execution continues for the remaining records.
------------------------------------------------------------
Inputs:
    - User inputs at runtime:
        * RUN_MODE: train (0) / predict (1)
        * Model type: linear (1) / nonlinear (0)
        * Column height(s): one or multiple values (e.g., 3 4 5)

    - Earthquake records:
        Output/1_IDA_Records_train/*.AT2   (for train mode)
        Output/1_IDA_Records_predict/*.AT2 (for predict mode)

    - Dependent scripts (called via exec/import):
        * model_linear.py / model_nonlinear.py
        * defineDamping.py
        * defineRecorders.py
        * ReadRecord.py  (ReadRecord function)
        * doDynamicAnalysis.py (doDynamicAnalysis function)

    - Key environment variables set by this script:
        * RUN_MODE  : 'train' or 'predict'
        * IS_LINEAR : '1' or '0'
        * H_COL     : column height value for model scripts
------------------------------------------------------------
Outputs:
    - THA results saved per height and per record:
        Output/2_THA_train_linear/H*/<record_name>/
        Output/2_THA_train_nonlinear/H*/<record_name>/
        Output/2_THA_predict_linear/H*/<record_name>/
        Output/2_THA_predict_nonlinear/H*/<record_name>/

      (Exact files depend on defineRecorders.py, typically
       time-history outputs such as displacement/acceleration/
       forces, etc.)

    - Failed record logs per height (text file in run folder):
        failed_records_<mode>_<linear/nonlinear>_<Htag>.txt
------------------------------------------------------------
Changes since previous version:
    - Added unified train/predict switch to route inputs and
      outputs automatically.
    - Added linear/nonlinear switch to execute the correct
      model definition.
    - Added multi-height batch execution (loop over heights).
    - Added per-record subfolder outputs for cleaner dataset
      organization and traceability.
    - Added failure logging without stopping the full run.
------------------------------------------------------------
Impact of changes:
    - Enables systematic dataset generation across multiple
      structural configurations (different heights).
    - Improves reproducibility and experiment traceability by
      enforcing a consistent folder hierarchy.
    - Reduces manual effort and prevents mixing outputs across
      modes (train vs predict) and model types.
    - Makes large batch THA runs more robust (continues after
      individual record failures).
------------------------------------------------------------
Status:
    Stable (Batch processing / Dataset generation)

------------------------------------------------------------
Notes:
    - This script deletes and recreates the output folder for
      each height at the start of execution; previous results
      for that height will be removed.
    - Scaling factor is set as: scaleFac = 10 * 9.81.
    - Ground motions are applied using UniformExcitation with
      a Path timeSeries generated from transformed record data.
    - Recorder definitions fully control which response
      quantities are saved.
"""




# # -*- coding: utf-8 -*-
# import sys, io

# # âœ… Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ UnicodeEncodeError Ø¯Ø± Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù (SpyderØŒ CMDØŒ Run-Codes)
# if hasattr(sys.stdout, "buffer"):
#     sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='ignore')

# import os
# import shutil
# from openseespy.opensees import *
# from ReadRecord import ReadRecord
# from analyzeAndAnimate import analyzeAndAnimateTHA
# import vfo.vfo as vfo
# import opsvis as opsv
# from doDynamicAnalysis import doDynamicAnalysis

# # ------------------------------------------------------------
# # ğŸ”§ Ø§Ù†ØªØ®Ø§Ø¨ Ø­Ø§Ù„Øª train / predict
# # ------------------------------------------------------------
# choice = input("Ø¨Ø±Ø§ÛŒ train Ø¹Ø¯Ø¯ 0 Ùˆ Ø¨Ø±Ø§ÛŒ predict Ø¹Ø¯Ø¯ 1 Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†: ").strip()
# if choice == "0":
#     RUN_MODE = "train"
# elif choice == "1":
#     RUN_MODE = "predict"
# else:
#     print("âŒ ÙÙ‚Ø· Ø¹Ø¯Ø¯ 0 ÛŒØ§ 1 Ù…Ø¬Ø§Ø² Ø§Ø³Øª.")
#     sys.exit(1)

# # ------------------------------------------------------------
# # ğŸ”§ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ø®Ø·ÛŒ / ØºÛŒØ±Ø®Ø·ÛŒ
# # ------------------------------------------------------------
# lin_choice = input("Ù…Ø¯Ù„ Ø®Ø·ÛŒ Ø¨Ø§Ø´Ø¯ ÛŒØ§ ØºÛŒØ±Ø®Ø·ÛŒØŸ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ø®Ø·ÛŒ Ø¹Ø¯Ø¯ 1 Ùˆ Ø¨Ø±Ø§ÛŒ ØºÛŒØ±Ø®Ø·ÛŒ Ø¹Ø¯Ø¯ 0 Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†: ").strip()
# IS_LINEAR = (lin_choice == "1")

# print(f"ğŸ“Œ Ø­Ø§Ù„Øª Ø§Ø¬Ø±Ø§: {RUN_MODE} | Ù…Ø¯Ù„: {'Ø®Ø·ÛŒ' if IS_LINEAR else 'ØºÛŒØ±Ø®Ø·ÛŒ'}")

# # Ù‡Ù…Ú†Ù†ÛŒÙ† Ø¨Ù‡ Ù…Ø¯Ù„ Ø®Ø¨Ø± Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
# os.environ["RUN_MODE"] = RUN_MODE
# os.environ["IS_LINEAR"] = "1" if IS_LINEAR else "0"

# # ------------------------------------------------------------
# # ğŸ“ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø±ØªÙØ§Ø¹ Ø³ØªÙˆÙ† (ÛŒÚ© ÛŒØ§ Ú†Ù†Ø¯ Ù…Ù‚Ø¯Ø§Ø±)
# # ------------------------------------------------------------
# heights_raw = input("Ø§Ø±ØªÙØ§Ø¹ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù† (Ù…Ø«Ù„Ø§Ù‹: 3 ÛŒØ§ 3 4 5): ").strip()

# if not heights_raw:
#     print("âš ï¸ Ù‡ÛŒÚ† Ø§Ø±ØªÙØ§Ø¹ÛŒ ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯Ø› Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ 3 Ù…ØªØ± Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
#     heights = [3.0]
# else:
#     heights = []
#     for token in heights_raw.replace(',', ' ').split():
#         try:
#             h_val = float(token)
#             heights.append(h_val)
#         except ValueError:
#             print(f"âš ï¸ Ù…Ù‚Ø¯Ø§Ø± Â«{token}Â» Ø¹Ø¯Ø¯ Ù…Ø¹ØªØ¨Ø±ÛŒ Ù†ÛŒØ³Øª Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

#     if not heights:
#         print("âŒ Ù‡ÛŒÚ† Ø§Ø±ØªÙØ§Ø¹ Ù…Ø¹ØªØ¨Ø±ÛŒ ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯. Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
#         sys.exit(1)

# print("ğŸ“ Ø§Ø±ØªÙØ§Ø¹â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:", ", ".join(str(h) for h in heights))

# # ------------------------------------------------------------
# # âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ØªØ­Ù„ÛŒÙ„
# # ------------------------------------------------------------
# scaleFac = 10 * 9.81
# TFree = 0
# dataDirRoot = '../../'

# # ---------------------- Ù¾ÙˆØ´Ù‡Ù” ÙˆØ±ÙˆØ¯ÛŒ GM Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø§Ù„Øª ----------------------
# if RUN_MODE == 'train':
#     GMFolder = os.path.join(dataDirRoot, 'Output', '1_IDA_Records_train')
# else:
#     GMFolder = os.path.join(dataDirRoot, 'Output', '1_IDA_Records_predict')

# # ---------------------- Ù¾ÙˆØ´Ù‡Ù” Ø®Ø±ÙˆØ¬ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø§Ù„Øª Ùˆ Ø®Ø·ÛŒ/ØºÛŒØ±Ø®Ø·ÛŒ ----------------------
# if RUN_MODE == 'train':
#     if IS_LINEAR:
#         dataDirBase = os.path.join(dataDirRoot, 'Output', '2_THA_train_linear')
#     else:
#         dataDirBase = os.path.join(dataDirRoot, 'Output', '2_THA_train_nonlinear')
# else:  # predict
#     if IS_LINEAR:
#         dataDirBase = os.path.join(dataDirRoot, 'Output', '2_THA_predict_linear')
#     else:
#         dataDirBase = os.path.join(dataDirRoot, 'Output', '2_THA_predict_nonlinear')

# showAnimationDeform = 0

# print(f"ğŸ“¥ Ù¾ÙˆØ´Ù‡ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ: {GMFolder}")
# print(f"ğŸ“‚ Ù¾ÙˆØ´Ù‡ Ù¾Ø§ÛŒÙ‡â€ŒÛŒ Ø®Ø±ÙˆØ¬ÛŒ THA: {dataDirBase}\n")

# # ------------------------------------------------------------
# # âœ³ï¸ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ .AT2
# # ------------------------------------------------------------
# if not os.path.isdir(GMFolder):
#     raise FileNotFoundError(f"âŒ Ù¾ÙˆØ´Ù‡ ÙˆØ±ÙˆØ¯ÛŒ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {GMFolder}")

# all_records = [f for f in os.listdir(GMFolder) if f.endswith('.AT2')]
# print(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡: {len(all_records)}")

# # ------------------------------------------------------------
# # ğŸš€ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø§Ø±ØªÙØ§Ø¹ Ùˆ Ù‡Ø± Ø±Ú©ÙˆØ±Ø¯
# # ------------------------------------------------------------
# for h_val in heights:
    # ØªÙ†Ø¸ÛŒÙ… Ø§Ø±ØªÙØ§Ø¹ Ø³ØªÙˆÙ† Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ (Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ Ø¨Ø±Ø§ÛŒ model_linear.py Ùˆ model_nonlinear.py)
#     os.environ["H_COL"] = str(h_val)

    # Ø³Ø§Ø®Øª Ù†Ø§Ù… Ù¾ÙˆØ´Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
#     if float(h_val).is_integer():
#         h_tag = f"H{int(h_val)}"          # Ù…Ø«Ø§Ù„: H3
#     else:
#         h_tag = "H" + str(h_val).replace('.', 'p')   # Ù…Ø«Ø§Ù„: H3p5

    # Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø®ØµÙˆØµ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
#     dataDirOut = os.path.join(dataDirBase, h_tag)

    # Ù„ÛŒØ³Øª Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ù…Ø®ØµÙˆØµ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
#     failed_records = []

#     print(f"ğŸ—ï¸ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªÙØ§Ø¹ Ø³ØªÙˆÙ† {h_val} Ù…ØªØ± Ø¯Ø± Ù¾ÙˆØ´Ù‡: {dataDirOut}")

    # ğŸ§¹ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø®ØµÙˆØµ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
#     if os.path.exists(dataDirOut):
#         print(f"ğŸ§¹ Ø­Ø°Ù Ù…Ø­ØªÙˆØ§ÛŒ Ù‚Ø¨Ù„ÛŒ Ù¾ÙˆØ´Ù‡: {dataDirOut}")
#         shutil.rmtree(dataDirOut)
#     os.makedirs(dataDirOut, exist_ok=True)

    # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ú©ÙˆØ±Ø¯
#     for i, rec_file in enumerate(all_records, start=1):
#         try:
#             record_name = os.path.splitext(rec_file)[0]  # Ù…Ø«Ù„Ø§Ù‹: RSN4_..._x1_0
#             inFileName = os.path.join(GMFolder, rec_file)
#             GMPath = os.path.join(GMFolder, record_name + ".txt")

            # Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø®ØµÙˆØµ Ø§ÛŒÙ† Ø±Ú©ÙˆØ±Ø¯ (Ø²ÛŒØ±Ù¾ÙˆØ´Ù‡â€ŒØ§ÛŒ Ø¯Ø§Ø®Ù„ Ù¾ÙˆØ´Ù‡ Ø§Ø±ØªÙØ§Ø¹)
#             dataDir_rec = os.path.join(dataDirOut, record_name)
#             os.makedirs(dataDir_rec, exist_ok=True)

#             # âš¡ RecorderÙ‡Ø§ Ø§Ø² Ø§ÛŒÙ† Ù…ØªØºÛŒØ± Ø¨Ø±Ø§ÛŒ Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
#             dataDir = dataDir_rec

            # ğŸ”¹ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„ (Ø®Ø·ÛŒ ÛŒØ§ ØºÛŒØ±Ø®Ø·ÛŒ) Ùˆ Ù…ÛŒØ±Ø§ÛŒÛŒ
#             if IS_LINEAR:
#                 exec(io.open("model_linear.py", "r", encoding="utf-8").read())
#             else:
#                 exec(open("model_nonlinear.py").read())

#             exec(open("defineDamping.py").read())
#             exec(open("defineRecorders.py").read())

            # ğŸ”¹ Ø®ÙˆØ§Ù†Ø¯Ù† Ø±Ú©ÙˆØ±Ø¯ Ø²Ù„Ø²Ù„Ù‡ Ùˆ Ø§Ø¹Ù…Ø§Ù„ Ø¨Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ
#             transformed_path = os.path.join(GMFolder, "transformed")
#             os.makedirs(transformed_path, exist_ok=True)

#             dtInput, numPoints = ReadRecord(inFileName, GMPath)
#             seriesTag = 2
#             timeSeries('Path', seriesTag, '-dt', dtInput, '-filePath', GMPath, '-factor', scaleFac)
#             GMDir = 1
#             pattern('UniformExcitation', 2, GMDir, '-accel', seriesTag)

            # ğŸ”¹ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯ÛŒÙ†Ø§Ù…ÛŒÚ©ÛŒ
#             Tmax = numPoints * dtInput + TFree
#             dtAnalysis = dtInput

#             mode_str = "train" if RUN_MODE == "train" else "predict"
#             lin_str = "Ø®Ø·ÛŒ" if IS_LINEAR else "ØºÛŒØ±Ø®Ø·ÛŒ"
#             print(f"âš™ï¸ Ø§Ø±ØªÙØ§Ø¹ H = {h_val} m | Ø§Ø¬Ø±Ø§ÛŒ Ø±Ú©ÙˆØ±Ø¯ {i}/{len(all_records)}: {record_name}  ({mode_str}, {lin_str})")

#             doDynamicAnalysis(Tmax, dtInput)
#             wipe()

#             print(f"âœ… Ø§Ø±ØªÙØ§Ø¹ H = {h_val} m | Ø±Ú©ÙˆØ±Ø¯ {record_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯. ({mode_str}, {lin_str})\n")

#         except Exception as e:
#             print(f'âŒ Ø§Ø±ØªÙØ§Ø¹ H = {h_val} m | Ø®Ø·Ø§ Ø¯Ø± Ø±Ú©ÙˆØ±Ø¯ {rec_file}: {e}')
#             failed_records.append(rec_file)

    # âœï¸ Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒØ³Øª Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
#     failed_suffix = f"_{RUN_MODE}_{'linear' if IS_LINEAR else 'nonlinear'}_{h_tag}"
#     failed_file_name = f"failed_records{failed_suffix}.txt"

#     with open(failed_file_name, "w", encoding="utf-8") as f:
#         for rec in failed_records:
#             f.write(f"{rec}\n")

#     print(f"ğŸ“„ Ù„ÛŒØ³Øª Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªÙØ§Ø¹ {h_val} Ù…ØªØ± Ø¯Ø± ÙØ§ÛŒÙ„ {failed_file_name} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

# print(f"ğŸ Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø§Ø±ØªÙØ§Ø¹â€ŒÙ‡Ø§ ØªÙ…Ø§Ù… Ø´Ø¯. Ø­Ø§Ù„Øª Ø§Ø¬Ø±Ø§: {RUN_MODE} | Ù…Ø¯Ù„: {'Ø®Ø·ÛŒ' if IS_LINEAR else 'ØºÛŒØ±Ø®Ø·ÛŒ'}")




# -*- coding: utf-8 -*-
import sys, io

# âœ… Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ UnicodeEncodeError Ø¯Ø± Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù (SpyderØŒ CMDØŒ Run-Codes)
if hasattr(sys.stdout, "buffer"):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='ignore')

import os
import shutil

# ============================================================
# âœ… Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯: Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ø¬Ø§Ø¨Ù‡â€ŒØ¬Ø§ÛŒÛŒ ÙØ§ÛŒÙ„ Ø¨ÛŒÙ†:
#   Model\Time History Analysis (THA)  â†”  Model
# ============================================================

# Ù…Ø³ÛŒØ± ÙÙˆÙ„Ø¯Ø± Ù‡Ù…ÛŒÙ† ÙØ§ÛŒÙ„ (Ù‡Ø±Ø¬Ø§ Ø¨Ø§Ø´Ø¯)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Ø§Ú¯Ø± Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø±Ø§ Ø¨Ù‡ Model Ù…Ù†ØªÙ‚Ù„ Ú©Ù†ÛŒØŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ THA Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§ÛŒÙ†Ø¬Ø§ Ù‡Ø³ØªÙ†Ø¯:
THA_DIR = os.path.join(BASE_DIR, "Time History Analysis (THA)")

# Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ importÙ‡Ø§ÛŒ Ø²ÛŒØ± (ReadRecord, doDynamicAnalysis, ...) Ù‡Ù…ÛŒØ´Ù‡ Ú©Ø§Ø± Ú©Ù†Ù†Ø¯:
# - Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø¯Ø§Ø®Ù„ THA Ø¨Ø§Ø´Ø¯: BASE_DIR Ù‡Ù…Ø§Ù† THA_DIR ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³Øª
# - Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø¯Ø§Ø®Ù„ Model Ø¨Ø§Ø´Ø¯: THA_DIR ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
if os.path.isdir(THA_DIR) and THA_DIR not in sys.path:
    sys.path.insert(0, THA_DIR)

# Ø®ÙˆØ¯ BASE_DIR Ø±Ø§ Ù‡Ù… Ø¯Ø± sys.path Ø¨Ú¯Ø°Ø§Ø± (Ø§ÛŒÙ…Ù†)
if BASE_DIR not in sys.path:
    sys.path.insert(0, BASE_DIR)

def find_project_root(start_dir: str, max_up: int = 6) -> str:
    """
    Ø±ÛŒØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯: Ø¬Ø§ÛŒÛŒ Ú©Ù‡ Ù¾ÙˆØ´Ù‡ Output ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.
    """
    cur = os.path.abspath(start_dir)
    for _ in range(max_up):
        if os.path.isdir(os.path.join(cur, "Output")):
            return cur
        parent = os.path.dirname(cur)
        if parent == cur:
            break
        cur = parent
    # Ø§Ú¯Ø± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ù‡Ù…Ø§Ù† Ø±ÙØªØ§Ø± Ù‚Ø¨Ù„ÛŒ Ø±Ø§ ØªØ§ Ø­Ø¯ Ù…Ù…Ú©Ù† Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    # (Ø§Ù…Ø§ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù¾Ø±ÙˆÚ˜Ù‡ Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒÚ¯Ø±ÛŒ Ø¯Ø§Ø±Ø¯)
    return os.path.abspath(start_dir)

PROJECT_ROOT = find_project_root(BASE_DIR)

def locate_dep(filename: str) -> str:
    """
    ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ø¨Ø³ØªÙ‡ Ø±Ø§ Ø¯Ø± Ø§ÛŒÙ† Ù…Ø³ÛŒØ±Ù‡Ø§ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:
      1) Ú©Ù†Ø§Ø± Ù‡Ù…ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª
      2) Ø¯Ø§Ø®Ù„ Time History Analysis (THA) (Ø§Ú¯Ø± Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¯Ø§Ø®Ù„ Model Ø¨Ø§Ø´Ø¯)
    """
    c1 = os.path.join(BASE_DIR, filename)
    if os.path.exists(c1):
        return c1
    c2 = os.path.join(THA_DIR, filename)
    if os.path.exists(c2):
        return c2
    # Ø§Ú¯Ø± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ù‡Ù…Ø§Ù† Ø§Ø³Ù… Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ… ØªØ§ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ÛŒ Ø·Ø¨ÛŒØ¹ÛŒ Ø¨Ø¯Ù‡Ø¯
    return filename

# ============================================================
# Ø­Ø§Ù„Ø§ importÙ‡Ø§ (Ø¨Ø¹Ø¯ Ø§Ø² sys.path ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡)
# ============================================================
from openseespy.opensees import *
from ReadRecord import ReadRecord
from analyzeAndAnimate import analyzeAndAnimateTHA
import vfo.vfo as vfo
import opsvis as opsv
from doDynamicAnalysis import doDynamicAnalysis

# ------------------------------------------------------------
# ğŸ”§ Ø§Ù†ØªØ®Ø§Ø¨ Ø­Ø§Ù„Øª train / predict
# ------------------------------------------------------------
choice = input("Ø¨Ø±Ø§ÛŒ train Ø¹Ø¯Ø¯ 0 Ùˆ Ø¨Ø±Ø§ÛŒ predict Ø¹Ø¯Ø¯ 1 Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†: ").strip()
if choice == "0":
    RUN_MODE = "train"
elif choice == "1":
    RUN_MODE = "predict"
else:
    print("âŒ ÙÙ‚Ø· Ø¹Ø¯Ø¯ 0 ÛŒØ§ 1 Ù…Ø¬Ø§Ø² Ø§Ø³Øª.")
    sys.exit(1)

# ------------------------------------------------------------
# ğŸ”§ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ø®Ø·ÛŒ / ØºÛŒØ±Ø®Ø·ÛŒ
# ------------------------------------------------------------
lin_choice = input("Ù…Ø¯Ù„ Ø®Ø·ÛŒ Ø¨Ø§Ø´Ø¯ ÛŒØ§ ØºÛŒØ±Ø®Ø·ÛŒØŸ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ø®Ø·ÛŒ Ø¹Ø¯Ø¯ 1 Ùˆ Ø¨Ø±Ø§ÛŒ ØºÛŒØ±Ø®Ø·ÛŒ Ø¹Ø¯Ø¯ 0 Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†: ").strip()
IS_LINEAR = (lin_choice == "1")

print(f"ğŸ“Œ Ø­Ø§Ù„Øª Ø§Ø¬Ø±Ø§: {RUN_MODE} | Ù…Ø¯Ù„: {'Ø®Ø·ÛŒ' if IS_LINEAR else 'ØºÛŒØ±Ø®Ø·ÛŒ'}")

# Ù‡Ù…Ú†Ù†ÛŒÙ† Ø¨Ù‡ Ù…Ø¯Ù„ Ø®Ø¨Ø± Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
os.environ["RUN_MODE"] = RUN_MODE
os.environ["IS_LINEAR"] = "1" if IS_LINEAR else "0"

# ------------------------------------------------------------
# ğŸ“ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø±ØªÙØ§Ø¹ Ø³ØªÙˆÙ† (ÛŒÚ© ÛŒØ§ Ú†Ù†Ø¯ Ù…Ù‚Ø¯Ø§Ø±)
# ------------------------------------------------------------
heights_raw = input("Ø§Ø±ØªÙØ§Ø¹ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù† (Ù…Ø«Ù„Ø§Ù‹: 3 ÛŒØ§ 3 4 5): ").strip()

if not heights_raw:
    print("âš ï¸ Ù‡ÛŒÚ† Ø§Ø±ØªÙØ§Ø¹ÛŒ ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯Ø› Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ 3 Ù…ØªØ± Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    heights = [3.0]
else:
    heights = []
    for token in heights_raw.replace(',', ' ').split():
        try:
            h_val = float(token)
            heights.append(h_val)
        except ValueError:
            print(f"âš ï¸ Ù…Ù‚Ø¯Ø§Ø± Â«{token}Â» Ø¹Ø¯Ø¯ Ù…Ø¹ØªØ¨Ø±ÛŒ Ù†ÛŒØ³Øª Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

    if not heights:
        print("âŒ Ù‡ÛŒÚ† Ø§Ø±ØªÙØ§Ø¹ Ù…Ø¹ØªØ¨Ø±ÛŒ ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯. Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
        sys.exit(1)

print("ğŸ“ Ø§Ø±ØªÙØ§Ø¹â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:", ", ".join(str(h) for h in heights))

# ------------------------------------------------------------
# âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ØªØ­Ù„ÛŒÙ„
# ------------------------------------------------------------
scaleFac = 10 * 9.81
TFree = 0

# âœ… Ù‚Ø¨Ù„Ø§Ù‹: dataDirRoot = '../../'
# âœ… Ø§Ù„Ø§Ù†: Ø±ÛŒØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø±Ø§ Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
dataDirRoot = PROJECT_ROOT

# ---------------------- Ù¾ÙˆØ´Ù‡Ù” ÙˆØ±ÙˆØ¯ÛŒ GM Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø§Ù„Øª ----------------------
if RUN_MODE == 'train':
    GMFolder = os.path.join(dataDirRoot, 'Output', '1_IDA_Records_train')
else:
    GMFolder = os.path.join(dataDirRoot, 'Output', '1_IDA_Records_predict')

# ---------------------- Ù¾ÙˆØ´Ù‡Ù” Ø®Ø±ÙˆØ¬ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø§Ù„Øª Ùˆ Ø®Ø·ÛŒ/ØºÛŒØ±Ø®Ø·ÛŒ ----------------------
if RUN_MODE == 'train':
    if IS_LINEAR:
        dataDirBase = os.path.join(dataDirRoot, 'Output', '2_THA_train_linear')
    else:
        dataDirBase = os.path.join(dataDirRoot, 'Output', '2_THA_train_nonlinear')
else:  # predict
    if IS_LINEAR:
        dataDirBase = os.path.join(dataDirRoot, 'Output', '2_THA_predict_linear')
    else:
        dataDirBase = os.path.join(dataDirRoot, 'Output', '2_THA_predict_nonlinear')

showAnimationDeform = 0

print(f"ğŸ“¥ Ù¾ÙˆØ´Ù‡ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ: {GMFolder}")
print(f"ğŸ“‚ Ù¾ÙˆØ´Ù‡ Ù¾Ø§ÛŒÙ‡â€ŒÛŒ Ø®Ø±ÙˆØ¬ÛŒ THA: {dataDirBase}\n")

# ------------------------------------------------------------
# âœ³ï¸ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ .AT2
# ------------------------------------------------------------
if not os.path.isdir(GMFolder):
    raise FileNotFoundError(f"âŒ Ù¾ÙˆØ´Ù‡ ÙˆØ±ÙˆØ¯ÛŒ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {GMFolder}")

all_records = [f for f in os.listdir(GMFolder) if f.endswith('.AT2')]
print(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡: {len(all_records)}")

# ------------------------------------------------------------
# ğŸš€ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø§Ø±ØªÙØ§Ø¹ Ùˆ Ù‡Ø± Ø±Ú©ÙˆØ±Ø¯
# ------------------------------------------------------------
for h_val in heights:
    # ØªÙ†Ø¸ÛŒÙ… Ø§Ø±ØªÙØ§Ø¹ Ø³ØªÙˆÙ† Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ (Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ Ø¨Ø±Ø§ÛŒ model_linear.py Ùˆ model_nonlinear.py)
    os.environ["H_COL"] = str(h_val)

    # Ø³Ø§Ø®Øª Ù†Ø§Ù… Ù¾ÙˆØ´Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
    if float(h_val).is_integer():
        h_tag = f"H{int(h_val)}"          # Ù…Ø«Ø§Ù„: H3
    else:
        h_tag = "H" + str(h_val).replace('.', 'p')   # Ù…Ø«Ø§Ù„: H3p5

    # Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø®ØµÙˆØµ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
    dataDirOut = os.path.join(dataDirBase, h_tag)

    # Ù„ÛŒØ³Øª Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ù…Ø®ØµÙˆØµ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
    failed_records = []

    print(f"ğŸ—ï¸ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªÙØ§Ø¹ Ø³ØªÙˆÙ† {h_val} Ù…ØªØ± Ø¯Ø± Ù¾ÙˆØ´Ù‡: {dataDirOut}")

    # ğŸ§¹ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø®ØµÙˆØµ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
    if os.path.exists(dataDirOut):
        print(f"ğŸ§¹ Ø­Ø°Ù Ù…Ø­ØªÙˆØ§ÛŒ Ù‚Ø¨Ù„ÛŒ Ù¾ÙˆØ´Ù‡: {dataDirOut}")
        shutil.rmtree(dataDirOut)
    os.makedirs(dataDirOut, exist_ok=True)

    # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ú©ÙˆØ±Ø¯
    for i, rec_file in enumerate(all_records, start=1):
        try:
            record_name = os.path.splitext(rec_file)[0]  # Ù…Ø«Ù„Ø§Ù‹: RSN4_..._x1_0
            inFileName = os.path.join(GMFolder, rec_file)
            GMPath = os.path.join(GMFolder, record_name + ".txt")

            # Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø®ØµÙˆØµ Ø§ÛŒÙ† Ø±Ú©ÙˆØ±Ø¯ (Ø²ÛŒØ±Ù¾ÙˆØ´Ù‡â€ŒØ§ÛŒ Ø¯Ø§Ø®Ù„ Ù¾ÙˆØ´Ù‡ Ø§Ø±ØªÙØ§Ø¹)
            dataDir_rec = os.path.join(dataDirOut, record_name)
            os.makedirs(dataDir_rec, exist_ok=True)

            # âš¡ RecorderÙ‡Ø§ Ø§Ø² Ø§ÛŒÙ† Ù…ØªØºÛŒØ± Ø¨Ø±Ø§ÛŒ Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
            dataDir = dataDir_rec

            # ğŸ”¹ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„ (Ø®Ø·ÛŒ ÛŒØ§ ØºÛŒØ±Ø®Ø·ÛŒ) Ùˆ Ù…ÛŒØ±Ø§ÛŒÛŒ
            if IS_LINEAR:
                exec(io.open(locate_dep("model_linear.py"), "r", encoding="utf-8").read())
            else:
                exec(open(locate_dep("model_nonlinear.py"), "r", encoding="utf-8").read())

            exec(open(locate_dep("defineDamping.py"), "r", encoding="utf-8").read())
            exec(open(locate_dep("defineRecorders.py"), "r", encoding="utf-8").read())

            # ğŸ”¹ Ø®ÙˆØ§Ù†Ø¯Ù† Ø±Ú©ÙˆØ±Ø¯ Ø²Ù„Ø²Ù„Ù‡ Ùˆ Ø§Ø¹Ù…Ø§Ù„ Ø¨Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ
            transformed_path = os.path.join(GMFolder, "transformed")
            os.makedirs(transformed_path, exist_ok=True)

            dtInput, numPoints = ReadRecord(inFileName, GMPath)
            seriesTag = 2
            timeSeries('Path', seriesTag, '-dt', dtInput, '-filePath', GMPath, '-factor', scaleFac)
            GMDir = 1
            pattern('UniformExcitation', 2, GMDir, '-accel', seriesTag)

            # ğŸ”¹ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯ÛŒÙ†Ø§Ù…ÛŒÚ©ÛŒ
            Tmax = numPoints * dtInput + TFree
            dtAnalysis = dtInput

            mode_str = "train" if RUN_MODE == "train" else "predict"
            lin_str = "Ø®Ø·ÛŒ" if IS_LINEAR else "ØºÛŒØ±Ø®Ø·ÛŒ"
            print(f"âš™ï¸ Ø§Ø±ØªÙØ§Ø¹ H = {h_val} m | Ø§Ø¬Ø±Ø§ÛŒ Ø±Ú©ÙˆØ±Ø¯ {i}/{len(all_records)}: {record_name}  ({mode_str}, {lin_str})")

            doDynamicAnalysis(Tmax, dtInput)
            wipe()

            print(f"âœ… Ø§Ø±ØªÙØ§Ø¹ H = {h_val} m | Ø±Ú©ÙˆØ±Ø¯ {record_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯. ({mode_str}, {lin_str})\n")

        except Exception as e:
            print(f'âŒ Ø§Ø±ØªÙØ§Ø¹ H = {h_val} m | Ø®Ø·Ø§ Ø¯Ø± Ø±Ú©ÙˆØ±Ø¯ {rec_file}: {e}')
            failed_records.append(rec_file)

    # âœï¸ Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒØ³Øª Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ø±ØªÙØ§Ø¹
    failed_suffix = f"_{RUN_MODE}_{'linear' if IS_LINEAR else 'nonlinear'}_{h_tag}"
    failed_file_name = f"failed_records{failed_suffix}.txt"

    with open(failed_file_name, "w", encoding="utf-8") as f:
        for rec in failed_records:
            f.write(f"{rec}\n")

    print(f"ğŸ“„ Ù„ÛŒØ³Øª Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªÙØ§Ø¹ {h_val} Ù…ØªØ± Ø¯Ø± ÙØ§ÛŒÙ„ {failed_file_name} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

print(f"ğŸ Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø§Ø±ØªÙØ§Ø¹â€ŒÙ‡Ø§ ØªÙ…Ø§Ù… Ø´Ø¯. Ø­Ø§Ù„Øª Ø§Ø¬Ø±Ø§: {RUN_MODE} | Ù…Ø¯Ù„: {'Ø®Ø·ÛŒ' if IS_LINEAR else 'ØºÛŒØ±Ø®Ø·ÛŒ'}")
